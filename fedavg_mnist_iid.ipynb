{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=#6B49F5> A Simple Implementation of FedAvg with PyTorch on IIDÂ Data </font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import random\n",
    "import math\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from matplotlib import pyplot\n",
    "\n",
    "from pathlib import Path\n",
    "import requests\n",
    "import pickle\n",
    "import gzip\n",
    "\n",
    "import torch\n",
    "import math\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "pd.options.display.float_format = \"{:,.4f}\".format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's download data set\n",
    "DATA_PATH = Path(\"data\")\n",
    "PATH = DATA_PATH / \"mnist\"\n",
    "# PATH = os.join.path(p1, p2)\n",
    "PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "URL = \"http://deeplearning.net/data/mnist/\"\n",
    "FILENAME = \"mnist.pkl.gz\"\n",
    "\n",
    "if not (PATH / FILENAME).exists():\n",
    "        content = requests.get(URL + FILENAME).content\n",
    "        (PATH / FILENAME).open(\"wb\").write(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open((PATH / FILENAME).as_posix(), \"rb\") as f:\n",
    "        ((x_train, y_train), (x_valid, y_valid), (x_test, y_test)) = pickle.load(f, encoding=\"latin-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 784), (50000,), (10000, 784), (10000,), (10000, 784), (10000,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's see the dataset size\n",
    "x_train.shape, y_train.shape , x_valid.shape, y_valid.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's check how many of each tag are**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 >> train: 4932 , valid: 991 , test: 980 , total: 6903\n",
      "1 >> train: 5678 , valid: 1064 , test: 1135 , total: 7877\n",
      "2 >> train: 4968 , valid: 990 , test: 1032 , total: 6990\n",
      "3 >> train: 5101 , valid: 1030 , test: 1010 , total: 7141\n",
      "4 >> train: 4859 , valid: 983 , test: 982 , total: 6824\n",
      "5 >> train: 4506 , valid: 915 , test: 892 , total: 6313\n",
      "6 >> train: 4951 , valid: 967 , test: 958 , total: 6876\n",
      "7 >> train: 5175 , valid: 1090 , test: 1028 , total: 7293\n",
      "8 >> train: 4842 , valid: 1009 , test: 974 , total: 6825\n",
      "9 >> train: 4988 , valid: 961 , test: 1009 , total: 6958\n",
      "y_train_total= 50000\n",
      "y_valid_total= 10000\n",
      "y_test_total= 10000\n",
      "total= 70000\n"
     ]
    }
   ],
   "source": [
    "# Let's check how many of each tag are.\n",
    "y_train_total=0\n",
    "y_valid_total=0\n",
    "y_test_total=0\n",
    "total=0\n",
    "for i in range(10):\n",
    "    print(i,\">> train:\", sum(y_train==i), \", valid:\", sum(y_valid==i), \n",
    "          \", test:\", sum(y_test==i), \", total:\", sum(y_train==i)+sum(y_valid==i)+sum(y_test==i) )\n",
    "    y_train_total=y_train_total + sum(y_train==i)\n",
    "    y_valid_total=y_valid_total + sum(y_valid==i)\n",
    "    y_test_total=y_test_total + sum(y_test==i)\n",
    "    total=total+sum(y_train==i)+sum(y_valid==i)+sum(y_test==i)\n",
    "    \n",
    "print(\"y_train_total=\", y_train_total) \n",
    "print(\"y_valid_total=\", y_valid_total) \n",
    "print(\"y_test_total=\", y_test_total)\n",
    "print(\"total=\", total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_and_shuffle_labels(y_data, seed, amount):\n",
    "    y_data=pd.DataFrame(y_data,columns=[\"labels\"])\n",
    "    y_data[\"i\"]=np.arange(len(y_data))\n",
    "    label_dict = dict()\n",
    "    for i in range(10):\n",
    "        var_name=\"label\" + str(i)\n",
    "        label_info=y_data[y_data[\"labels\"]==i]\n",
    "        np.random.seed(seed)\n",
    "        label_info=np.random.permutation(label_info)\n",
    "        label_info=label_info[0:amount]\n",
    "        label_info=pd.DataFrame(label_info, columns=[\"labels\",\"i\"])\n",
    "        label_dict.update({var_name: label_info })\n",
    "    return label_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_iid_subsamples_indices(label_dict, number_of_samples, amount):\n",
    "    sample_dict= dict()\n",
    "    batch_size=int(math.floor(amount/number_of_samples))\n",
    "    for i in range(number_of_samples):\n",
    "        sample_name=\"sample\"+str(i)\n",
    "        dumb=pd.DataFrame()\n",
    "        for j in range(10):\n",
    "            label_name=str(\"label\")+str(j)\n",
    "            a=label_dict[label_name][i*batch_size:(i+1)*batch_size]\n",
    "            dumb=pd.concat([dumb,a], axis=0)\n",
    "        dumb.reset_index(drop=True, inplace=True)    \n",
    "        sample_dict.update({sample_name: dumb}) \n",
    "    return sample_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_iid_subsamples(sample_dict, x_data, y_data, x_name, y_name):\n",
    "    x_data_dict= dict()\n",
    "    y_data_dict= dict()\n",
    "    \n",
    "    for i in range(len(sample_dict)):  ### len(sample_dict)= number of samples\n",
    "        xname= x_name+str(i)\n",
    "        yname= y_name+str(i)\n",
    "        sample_name=\"sample\"+str(i)\n",
    "        \n",
    "        indices=np.sort(np.array(sample_dict[sample_name][\"i\"]))\n",
    "        \n",
    "        x_info= x_data[indices,:]\n",
    "        x_data_dict.update({xname : x_info})\n",
    "        \n",
    "        y_info= y_data[indices]\n",
    "        y_data_dict.update({yname : y_info})\n",
    "        \n",
    "    return x_data_dict, y_data_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------\n",
    "### <span style=\"background-color:#F087F9\"> Classification Model </span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net2nn(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net2nn, self).__init__()\n",
    "        self.fc1=nn.Linear(784,200)\n",
    "        self.fc2=nn.Linear(200,200)\n",
    "        self.fc3=nn.Linear(200,10)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x=F.relu(self.fc1(x))\n",
    "        x=F.relu(self.fc2(x))\n",
    "        x=self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WrappedDataLoader:\n",
    "    def __init__(self, dl, func):\n",
    "        self.dl = dl\n",
    "        self.func = func\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dl)\n",
    "\n",
    "    def __iter__(self):\n",
    "        batches = iter(self.dl)\n",
    "        for b in batches:\n",
    "            yield (self.func(*b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, criterion, optimizer):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    correct = 0\n",
    "\n",
    "    for data, target in train_loader:\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        prediction = output.argmax(dim=1, keepdim=True)\n",
    "        correct += prediction.eq(target.view_as(prediction)).sum().item()\n",
    "        \n",
    "\n",
    "    return train_loss / len(train_loader), correct/len(train_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model, test_loader, criterion):\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            output = model(data)\n",
    "            \n",
    "            test_loss += criterion(output, target).item()\n",
    "            prediction = output.argmax(dim=1, keepdim=True)\n",
    "            correct += prediction.eq(target.view_as(prediction)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader)\n",
    "    correct /= len(test_loader.dataset)\n",
    "\n",
    "    return (test_loss, correct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------\n",
    "### <span style=\"background-color:#F087F9\"> Functions for Federated Averaging </span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_optimizer_criterion_dict(number_of_samples):\n",
    "    model_dict = dict()\n",
    "    optimizer_dict= dict()\n",
    "    criterion_dict = dict()\n",
    "    \n",
    "    for i in range(number_of_samples):\n",
    "        model_name=\"model\"+str(i)\n",
    "        model_info=Net2nn()\n",
    "        model_dict.update({model_name : model_info })\n",
    "        \n",
    "        optimizer_name=\"optimizer\"+str(i)\n",
    "        optimizer_info = torch.optim.SGD(model_info.parameters(), lr=learning_rate, momentum=momentum)\n",
    "        optimizer_dict.update({optimizer_name : optimizer_info })\n",
    "        \n",
    "        criterion_name = \"criterion\"+str(i)\n",
    "        criterion_info = nn.CrossEntropyLoss()\n",
    "        criterion_dict.update({criterion_name : criterion_info})\n",
    "        \n",
    "    return model_dict, optimizer_dict, criterion_dict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_averaged_weights(model_dict, number_of_samples):\n",
    "   \n",
    "    fc1_mean_weight = torch.zeros(size=model_dict[name_of_models[0]].fc1.weight.shape)\n",
    "    fc1_mean_bias = torch.zeros(size=model_dict[name_of_models[0]].fc1.bias.shape)\n",
    "    \n",
    "    fc2_mean_weight = torch.zeros(size=model_dict[name_of_models[0]].fc2.weight.shape)\n",
    "    fc2_mean_bias = torch.zeros(size=model_dict[name_of_models[0]].fc2.bias.shape)\n",
    "    \n",
    "    fc3_mean_weight = torch.zeros(size=model_dict[name_of_models[0]].fc3.weight.shape)\n",
    "    fc3_mean_bias = torch.zeros(size=model_dict[name_of_models[0]].fc3.bias.shape)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "    \n",
    "        for i in range(number_of_samples):\n",
    "            fc1_mean_weight += model_dict[name_of_models[i]].fc1.weight.data.clone()\n",
    "            fc1_mean_bias += model_dict[name_of_models[i]].fc1.bias.data.clone()\n",
    "        \n",
    "            fc2_mean_weight += model_dict[name_of_models[i]].fc2.weight.data.clone()\n",
    "            fc2_mean_bias += model_dict[name_of_models[i]].fc2.bias.data.clone()\n",
    "        \n",
    "            fc3_mean_weight += model_dict[name_of_models[i]].fc3.weight.data.clone()\n",
    "            fc3_mean_bias += model_dict[name_of_models[i]].fc3.bias.data.clone()\n",
    "\n",
    "        \n",
    "        fc1_mean_weight =fc1_mean_weight/number_of_samples\n",
    "        fc1_mean_bias = fc1_mean_bias/ number_of_samples\n",
    "    \n",
    "        fc2_mean_weight =fc2_mean_weight/number_of_samples\n",
    "        fc2_mean_bias = fc2_mean_bias/ number_of_samples\n",
    "    \n",
    "        fc3_mean_weight =fc3_mean_weight/number_of_samples\n",
    "        fc3_mean_bias = fc3_mean_bias/ number_of_samples\n",
    "    \n",
    "    return fc1_mean_weight, fc1_mean_bias, fc2_mean_weight, fc2_mean_bias, fc3_mean_weight, fc3_mean_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_averaged_weights_as_main_model_weights_and_update_main_model(main_model,model_dict, number_of_samples):\n",
    "    fc1_mean_weight, fc1_mean_bias, fc2_mean_weight, fc2_mean_bias, fc3_mean_weight, fc3_mean_bias = get_averaged_weights(model_dict, number_of_samples=number_of_samples)\n",
    "    with torch.no_grad():\n",
    "        main_model.fc1.weight.data = fc1_mean_weight.data.clone()\n",
    "        main_model.fc2.weight.data = fc2_mean_weight.data.clone()\n",
    "        main_model.fc3.weight.data = fc3_mean_weight.data.clone()\n",
    "\n",
    "        main_model.fc1.bias.data = fc1_mean_bias.data.clone()\n",
    "        main_model.fc2.bias.data = fc2_mean_bias.data.clone()\n",
    "        main_model.fc3.bias.data = fc3_mean_bias.data.clone() \n",
    "    return main_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_local_and_merged_model_performance(number_of_samples):\n",
    "    accuracy_table=pd.DataFrame(data=np.zeros((number_of_samples,3)), columns=[\"sample\", \"local_ind_model\", \"merged_main_model\"])\n",
    "    for i in range (number_of_samples):\n",
    "    \n",
    "        test_ds = TensorDataset(x_test_dict[name_of_x_test_sets[i]], y_test_dict[name_of_y_test_sets[i]])\n",
    "        test_dl = DataLoader(test_ds, batch_size=batch_size * 2)\n",
    "    \n",
    "        model=model_dict[name_of_models[i]]\n",
    "        criterion=criterion_dict[name_of_criterions[i]]\n",
    "        optimizer=optimizer_dict[name_of_optimizers[i]]\n",
    "    \n",
    "        individual_loss, individual_accuracy = validation(model, test_dl, criterion)\n",
    "        main_loss, main_accuracy =validation(main_model, test_dl, main_criterion )\n",
    "    \n",
    "        accuracy_table.loc[i, \"sample\"]=\"sample \"+str(i)\n",
    "        accuracy_table.loc[i, \"local_ind_model\"] = individual_accuracy\n",
    "        accuracy_table.loc[i, \"merged_main_model\"] = main_accuracy\n",
    "\n",
    "    return accuracy_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_main_model_to_nodes_and_update_model_dict(main_model, model_dict, number_of_samples):\n",
    "    with torch.no_grad():\n",
    "        for i in range(number_of_samples):\n",
    "\n",
    "            model_dict[name_of_models[i]].fc1.weight.data =main_model.fc1.weight.data.clone()\n",
    "            model_dict[name_of_models[i]].fc2.weight.data =main_model.fc2.weight.data.clone()\n",
    "            model_dict[name_of_models[i]].fc3.weight.data =main_model.fc3.weight.data.clone() \n",
    "            \n",
    "            model_dict[name_of_models[i]].fc1.bias.data =main_model.fc1.bias.data.clone()\n",
    "            model_dict[name_of_models[i]].fc2.bias.data =main_model.fc2.bias.data.clone()\n",
    "            model_dict[name_of_models[i]].fc3.bias.data =main_model.fc3.bias.data.clone() \n",
    "    \n",
    "    return model_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_train_end_node_process(number_of_samples):\n",
    "    for i in range (number_of_samples): \n",
    "\n",
    "        train_ds = TensorDataset(x_train_dict[name_of_x_train_sets[i]], y_train_dict[name_of_y_train_sets[i]])\n",
    "        train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "#         valid_ds = TensorDataset(x_valid_dict[name_of_x_valid_sets[i]], y_valid_dict[name_of_y_valid_sets[i]])\n",
    "#         valid_dl = DataLoader(valid_ds, batch_size=batch_size * 2)\n",
    "        \n",
    "        test_ds = TensorDataset(x_test_dict[name_of_x_test_sets[i]], y_test_dict[name_of_y_test_sets[i]])\n",
    "        test_dl = DataLoader(test_ds, batch_size= batch_size * 2)\n",
    "    \n",
    "        model=model_dict[name_of_models[i]]\n",
    "        criterion=criterion_dict[name_of_criterions[i]]\n",
    "        optimizer=optimizer_dict[name_of_optimizers[i]]\n",
    "    \n",
    "        print(\"Subset\" ,i)\n",
    "        for epoch in range(numEpoch):        \n",
    "            train_loss, train_accuracy = train(model, train_dl, criterion, optimizer)\n",
    "#             valid_loss, valid_accuracy = validation(model, valid_dl, criterion)\n",
    "            test_loss, test_accuracy = validation(model, test_dl, criterion)\n",
    "    \n",
    "            print(\"epoch: {:3.0f}\".format(epoch+1) + \" | train accuracy: {:7.5f}\".format(train_accuracy) + \" | test accuracy: {:7.5f}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def start_train_end_node_process_without_print(number_of_samples):\n",
    "    for i in range (number_of_samples): \n",
    "\n",
    "        train_ds = TensorDataset(x_train_dict[name_of_x_train_sets[i]], y_train_dict[name_of_y_train_sets[i]])\n",
    "        train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "        test_ds = TensorDataset(x_test_dict[name_of_x_test_sets[i]], y_test_dict[name_of_y_test_sets[i]])\n",
    "        test_dl = DataLoader(test_ds, batch_size= batch_size * 2)\n",
    "    \n",
    "        model=model_dict[name_of_models[i]]\n",
    "        criterion=criterion_dict[name_of_criterions[i]]\n",
    "        optimizer=optimizer_dict[name_of_optimizers[i]]\n",
    "    \n",
    "        for epoch in range(numEpoch):        \n",
    "            train_loss, train_accuracy = train(model, train_dl, criterion, optimizer)\n",
    "            test_loss, test_accuracy = validation(model, test_dl, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_train_end_node_process_print_some(number_of_samples, print_amount):\n",
    "    for i in range (number_of_samples): \n",
    "\n",
    "        train_ds = TensorDataset(x_train_dict[name_of_x_train_sets[i]], y_train_dict[name_of_y_train_sets[i]])\n",
    "        train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "        test_ds = TensorDataset(x_test_dict[name_of_x_test_sets[i]], y_test_dict[name_of_y_test_sets[i]])\n",
    "        test_dl = DataLoader(test_ds, batch_size= batch_size * 2)\n",
    "    \n",
    "        model=model_dict[name_of_models[i]]\n",
    "        criterion=criterion_dict[name_of_criterions[i]]\n",
    "        optimizer=optimizer_dict[name_of_optimizers[i]]\n",
    "    \n",
    "        if i<print_amount:\n",
    "            print(\"Subset\" ,i)\n",
    "            \n",
    "        for epoch in range(numEpoch):\n",
    "        \n",
    "            train_loss, train_accuracy = train(model, train_dl, criterion, optimizer)\n",
    "            test_loss, test_accuracy = validation(model, test_dl, criterion)\n",
    "            \n",
    "            if i<print_amount:        \n",
    "                print(\"epoch: {:3.0f}\".format(epoch+1) + \" | train accuracy: {:7.5f}\".format(train_accuracy) + \" | test accuracy: {:7.5f}\".format(test_accuracy))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_valid, y_valid,x_test, y_test = map(torch.tensor, (x_train, y_train, x_valid, y_valid, x_test, y_test))\n",
    "number_of_samples=100\n",
    "learning_rate = 0.01\n",
    "numEpoch = 10\n",
    "batch_size = 32\n",
    "momentum = 0.9\n",
    "\n",
    "train_amount=4500\n",
    "valid_amount=900\n",
    "test_amount=900\n",
    "print_amount=3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------\n",
    "\n",
    "### <span style=\"background-color:#F087F9\"> Let's examine what would the performance of the centralized model be if the data were not distributed to nodes at all? </span>   \n",
    "\n",
    "The model used in this example is very simple, different things can be done to improve model performance, such as using more complex models, increasing epoch or hyperparameter tuning. However, the purpose here is to compare the performance of the main model that is formed by combining the parameters of the local models trained on their own data with a centralized model that trained on all training data. In this way, we can gain insight into the capacity of federated learning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "centralized_model = Net2nn()\n",
    "centralized_optimizer = torch.optim.SGD(centralized_model.parameters(), lr=0.01, momentum=0.9)\n",
    "centralized_criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = TensorDataset(x_train, y_train)\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "valid_ds = TensorDataset(x_valid, y_valid)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=batch_size * 2)\n",
    "\n",
    "test_ds = TensorDataset(x_test, y_test)\n",
    "test_dl = DataLoader(test_ds, batch_size=batch_size * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ Centralized Model ------\n",
      "epoch:   1 | train accuracy:  0.8772 | test accuracy:  0.9464\n",
      "epoch:   2 | train accuracy:  0.9548 | test accuracy:  0.9637\n",
      "epoch:   3 | train accuracy:  0.9706 | test accuracy:  0.9709\n",
      "epoch:   4 | train accuracy:  0.9785 | test accuracy:  0.9744\n",
      "epoch:   5 | train accuracy:  0.9828 | test accuracy:  0.9752\n",
      "epoch:   6 | train accuracy:  0.9866 | test accuracy:  0.9772\n",
      "epoch:   7 | train accuracy:  0.9887 | test accuracy:  0.9769\n",
      "epoch:   8 | train accuracy:  0.9919 | test accuracy:  0.9763\n",
      "epoch:   9 | train accuracy:  0.9937 | test accuracy:  0.9798\n",
      "epoch:  10 | train accuracy:  0.9954 | test accuracy:  0.9798\n",
      "------ Training finished ------\n"
     ]
    }
   ],
   "source": [
    "print(\"------ Centralized Model ------\")\n",
    "for epoch in range(numEpoch):\n",
    "    central_train_loss, central_train_accuracy = train(centralized_model, train_dl, centralized_criterion, centralized_optimizer)\n",
    "    central_test_loss, central_test_accuracy = validation(centralized_model, test_dl, centralized_criterion)\n",
    "    \n",
    "    print(\"epoch: {:3.0f}\".format(epoch+1) + \" | train accuracy: {:7.4f}\".format(central_train_accuracy) + \" | test accuracy: {:7.4f}\".format(central_test_accuracy))\n",
    "\n",
    "print(\"------ Training finished ------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "----------------\n",
    "-----------------\n",
    "**Data is distributed to nodes**\n",
    "\n",
    "<!-- ### <span style=\"background-color:#F087F9\"> DatanÄ±n nodelara daÄÄ±tÄ±lmasÄ± </span>    -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict_train=split_and_shuffle_labels(y_data=y_train, seed=1, amount=train_amount) \n",
    "sample_dict_train=get_iid_subsamples_indices(label_dict=label_dict_train, number_of_samples=number_of_samples, amount=train_amount)\n",
    "x_train_dict, y_train_dict = create_iid_subsamples(sample_dict=sample_dict_train, x_data=x_train, y_data=y_train, x_name=\"x_train\", y_name=\"y_train\")\n",
    "\n",
    "\n",
    "label_dict_valid = split_and_shuffle_labels(y_data=y_valid, seed=1, amount=train_amount) \n",
    "sample_dict_valid = get_iid_subsamples_indices(label_dict=label_dict_valid, number_of_samples=number_of_samples, amount=valid_amount)\n",
    "x_valid_dict, y_valid_dict = create_iid_subsamples(sample_dict=sample_dict_valid, x_data=x_valid, y_data=y_valid, x_name=\"x_valid\", y_name=\"y_valid\")\n",
    "\n",
    "label_dict_test = split_and_shuffle_labels(y_data=y_test, seed=1, amount=test_amount) \n",
    "sample_dict_test = get_iid_subsamples_indices(label_dict=label_dict_test, number_of_samples=number_of_samples, amount=test_amount)\n",
    "x_test_dict, y_test_dict = create_iid_subsamples(sample_dict=sample_dict_test, x_data=x_test, y_data=y_test, x_name=\"x_test\", y_name=\"y_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([450, 784]) torch.Size([450])\n",
      "torch.Size([90, 784]) torch.Size([90])\n",
      "torch.Size([90, 784]) torch.Size([90])\n",
      "tensor(1)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAMl0lEQVR4nO3dX6hd5Z3G8efRMbkwAfOHyNHKxAaRlmLtEEQwDB1KTRQkFuzQCMVa4fSiQg8IM0EvGpSCzkxn7iycojRTWktBS0My0oRYqlUMOREbE9PWNGTamEMSzUXMRdIe8+vFWSmnyd5rn6w/e+3k9/3AYe+93r3f9WORJ+9ae629XkeEAFz5ruq6AADDQdiBJAg7kARhB5Ig7EAS/zDMldnmq3+gZRHhXstrjey219n+ne2DtjfW6QtAu1z1PLvtqyX9XtIXJR2RtFvShoh4t+QzjOxAy9oY2e+QdDAiDkXEnyX9RNL6Gv0BaFGdsN8o6U9zXh8plv0d2+O2p2xP1VgXgJrqfEHXa1fhot30iJiUNCmxGw90qc7IfkTSTXNef0LS0XrlAGhLnbDvlnSL7ZttL5D0FUlbmikLQNMq78ZHxIztRyX9QtLVkp6PiP2NVQagUZVPvVVaGcfsQOtauagGwOWDsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkhjplMzDXqlWrStt37dpV2r579+7S9nvuueeSa7qSMbIDSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKcZ0erFi5c2LftySefLP3ssmXLStsXLVpUqaasaoXd9mFJH0n6WNJMRKxuoigAzWtiZP+XiPiggX4AtIhjdiCJumEPSdtt77E93usNtsdtT9meqrkuADXU3Y2/KyKO2l4haYft30bEq3PfEBGTkiYlyXbUXB+AimqN7BFxtHg8Lulnku5ooigAzascdtvX2l58/rmkuyXta6owAM1yRLU9a9uf1OxoLs0eDvw4Ir4z4DPsxiczNjbWt+3o0aO1+l67dm1p+/bt22v1f7mKCPdaXvmYPSIOSfps5YoADBWn3oAkCDuQBGEHkiDsQBKEHUiCn7iiluuuu660fdOmTZX7fuONN0rbX3nllcp9Z8TIDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJcJ4dtdx3332l7ePjPe9WNi9bt24tbZ+Zmancd0aM7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBOfZUeqGG24obX/iiScq933u3LnS9m3btlXuGxdjZAeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJDjPjlIPP/xwafutt95aue8tW7aUtu/du7dy37jYwJHd9vO2j9veN2fZUts7bL9XPC5pt0wAdc1nN/4HktZdsGyjpJ0RcYukncVrACNsYNgj4lVJJy9YvF7S5uL5Zkn3N1wXgIZVPWa/PiKmJSkipm2v6PdG2+OSqt+IDEAjWv+CLiImJU1Kku1oe30Aeqt66u2Y7TFJKh6PN1cSgDZUDfsWSQ8Vzx+S9PNmygHQloG78bZfkPR5ScttH5H0bUlPS/qp7Uck/VHSl9ssEu1ZsGBBafu6dReeiLk0Z8+e7dv2zDPP1Oobl2Zg2CNiQ5+mLzRcC4AWcbkskARhB5Ig7EAShB1IgrADSfAT1+TWrl1b2r5mzZpa/e/YsaNv25tvvlmrb1waRnYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSMIRw7t5DHeqGT0nTpwobV++fHmt/u+8886+bbt27arVN3qLCPdazsgOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0nwe/Yr3MqVK0vbFy5cWKv/l19+ubR9z549tfpHcxjZgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJzrNf4SYmJkrbFy9eXKv/bdu2lbbPzMzU6h/NGTiy237e9nHb++Ys22T7fdtvF3/3tlsmgLrmsxv/A0nreiz/n4i4vfj7v2bLAtC0gWGPiFclnRxCLQBaVOcLukdt7y1285f0e5PtcdtTtqdqrAtATVXD/j1JqyTdLmla0nf7vTEiJiNidUSsrrguAA2oFPaIOBYRH0fEOUnfl3RHs2UBaFqlsNsem/PyS5L29XsvgNEw8L7xtl+Q9HlJyyUdk/Tt4vXtkkLSYUnfiIjpgSvjvvGtKPvN+tRU+Vcly5YtK20/ePBgaXvZfeEl6cMPPyxtR/P63Td+4EU1EbGhx+LnalcEYKi4XBZIgrADSRB2IAnCDiRB2IEk+InrFWDp0qV92wadWhvk2WefLW3n1Nrlg5EdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5LgPPtl4Kqryv9Pfuyxxyr3febMmdL27du3V+4bo4WRHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeS4Dz7ZeCBBx4obX/wwQcr9z3oVtH79++v3DdGCyM7kARhB5Ig7EAShB1IgrADSRB2IAnCDiTBefbLwPr161vr+6mnnmqtb4yWgSO77Zts/9L2Adv7bX+rWL7U9g7b7xWPS9ovF0BV89mNn5H0WER8StKdkr5p+9OSNkraGRG3SNpZvAYwogaGPSKmI+Kt4vlHkg5IulHSekmbi7dtlnR/W0UCqO+Sjtltr5T0OUm7JF0fEdPS7H8Itlf0+cy4pPF6ZQKoa95ht71I0ouSJiLilO15fS4iJiVNFn1ElSIB1DevU2+2r9Fs0H8UES8Vi4/ZHivaxyQdb6dEAE1wRPlg69khfLOkkxExMWf5f0r6MCKetr1R0tKI+LcBfTGy93DbbbeVtr/++uul7YsWLaq87hUreh59/c2JEycq941uRETP3e757MbfJemrkt6x/Xax7HFJT0v6qe1HJP1R0pebKBRAOwaGPSJ+LanfAfoXmi0HQFu4XBZIgrADSRB2IAnCDiRB2IEk+InrCFi1alVpe53z6K+99lpp+6lTpyr3jcsLIzuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJMF59hFw6NCh0vbTp0+Xtp85c6Zv28TERN82STp79mxpO64cjOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kMTA+8Y3ujLuGw+0rt994xnZgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiCJgWG3fZPtX9o+YHu/7W8VyzfZft/228Xfve2XC6CqgRfV2B6TNBYRb9leLGmPpPsl/auk0xHxX/NeGRfVAK3rd1HNfOZnn5Y0XTz/yPYBSTc2Wx6Atl3SMbvtlZI+J2lXsehR23ttP297SZ/PjNuesj1Vq1IAtcz72njbiyT9StJ3IuIl29dL+kBSSHpKs7v6Xx/QB7vxQMv67cbPK+y2r5G0VdIvIuK/e7SvlLQ1Ij4zoB/CDrSs8g9hbFvSc5IOzA168cXdeV+StK9ukQDaM59v49dIek3SO5LOFYsfl7RB0u2a3Y0/LOkbxZd5ZX0xsgMtq7Ub3xTCDrSP37MDyRF2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSGHjDyYZ9IOn/57xeXiwbRaNa26jWJVFbVU3W9o/9Gob6e/aLVm5PRcTqzgooMaq1jWpdErVVNaza2I0HkiDsQBJdh32y4/WXGdXaRrUuidqqGkptnR6zAxierkd2AENC2IEkOgm77XW2f2f7oO2NXdTQj+3Dtt8ppqHudH66Yg6947b3zVm21PYO2+8Vjz3n2OuotpGYxrtkmvFOt13X058P/Zjd9tWSfi/pi5KOSNotaUNEvDvUQvqwfVjS6ojo/AIM2/8s6bSk/z0/tZbt/5B0MiKeLv6jXBIR/z4itW3SJU7j3VJt/aYZ/5o63HZNTn9eRRcj+x2SDkbEoYj4s6SfSFrfQR0jLyJelXTygsXrJW0unm/W7D+WoetT20iIiOmIeKt4/pGk89OMd7rtSuoaii7CfqOkP815fUSjNd97SNpue4/t8a6L6eH689NsFY8rOq7nQgOn8R6mC6YZH5ltV2X687q6CHuvqWlG6fzfXRHxT5LukfTNYncV8/M9Sas0OwfgtKTvdllMMc34i5ImIuJUl7XM1aOuoWy3LsJ+RNJNc15/QtLRDuroKSKOFo/HJf1Ms4cdo+TY+Rl0i8fjHdfzNxFxLCI+johzkr6vDrddMc34i5J+FBEvFYs733a96hrWdusi7Lsl3WL7ZtsLJH1F0pYO6riI7WuLL05k+1pJd2v0pqLeIumh4vlDkn7eYS1/Z1Sm8e43zbg63nadT38eEUP/k3SvZr+R/4OkJ7qooU9dn5T0m+Jvf9e1SXpBs7t1f9HsHtEjkpZJ2inpveJx6QjV9kPNTu29V7PBGuuotjWaPTTcK+nt4u/errddSV1D2W5cLgskwRV0QBKEHUiCsANJEHYgCcIOJEHYgSQIO5DEXwEQLtzuZWNTfQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(x_train_dict[\"x_train1\"].shape, y_train_dict[\"y_train1\"].shape)\n",
    "print(x_valid_dict[\"x_valid1\"].shape, y_valid_dict[\"y_valid1\"].shape) \n",
    "print(x_test_dict[\"x_test1\"].shape, y_test_dict[\"y_test1\"].shape)\n",
    "\n",
    "num_index = np.random.randint(test_amount/number_of_samples*10)\n",
    "pyplot.imshow(x_test_dict[\"x_test0\"][num_index].reshape((28,28)), cmap=\"gray\")\n",
    "print(y_test_dict[\"y_test0\"][num_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Main model is created**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_model = Net2nn()\n",
    "main_optimizer = torch.optim.SGD(main_model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "main_criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Models,optimizers and loss functions in nodes are defined**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict, optimizer_dict, criterion_dict = create_model_optimizer_criterion_dict(number_of_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Keys of dicts are being made iterable**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_of_x_train_sets=list(x_train_dict.keys())\n",
    "name_of_y_train_sets=list(y_train_dict.keys())\n",
    "name_of_x_valid_sets=list(x_valid_dict.keys())\n",
    "name_of_y_valid_sets=list(y_valid_dict.keys())\n",
    "name_of_x_test_sets=list(x_test_dict.keys())\n",
    "name_of_y_test_sets=list(y_test_dict.keys())\n",
    "\n",
    "name_of_models=list(model_dict.keys())\n",
    "name_of_optimizers=list(optimizer_dict.keys())\n",
    "name_of_criterions=list(criterion_dict.keys())\n",
    "\n",
    "# print(name_of_x_train_sets)\n",
    "# print(name_of_y_train_sets)\n",
    "# print(name_of_x_valid_sets)\n",
    "# print(name_of_y_valid_sets)\n",
    "# print(name_of_x_test_sets)\n",
    "# print(name_of_y_test_sets)\n",
    "# print(\"\\n ------------\")\n",
    "# print(name_of_models)\n",
    "# print(name_of_optimizers)\n",
    "# print(name_of_criterions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0088, -0.0085,  0.0256,  0.0047, -0.0443]],\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([[ 0.0697,  0.0439,  0.0521, -0.0573,  0.0217]],\n",
      "       grad_fn=<SliceBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(main_model.fc2.weight[0:1,0:5])\n",
    "print(model_dict[\"model1\"].fc2.weight[0:1,0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Parameters of main model are sent to nodes**  \n",
    "Since the parameters of the main model and parameters of all local models in the nodes are randomly initialized, all these parameters will be different from each other. For this reason, the main model sends its parameters to the nodes before the training of local models in the nodes begins. You can check the weights below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict=send_main_model_to_nodes_and_update_model_dict(main_model, model_dict, number_of_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0088, -0.0085,  0.0256,  0.0047, -0.0443]],\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([[-0.0088, -0.0085,  0.0256,  0.0047, -0.0443]],\n",
      "       grad_fn=<SliceBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(main_model.fc2.weight[0:1,0:5])\n",
    "print(model_dict[\"model1\"].fc2.weight[0:1,0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Models in the nodes are trained**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subset 0\n",
      "epoch:   1 | train accuracy: 0.10889 | test accuracy: 0.17778\n",
      "epoch:   2 | train accuracy: 0.17111 | test accuracy: 0.16667\n",
      "epoch:   3 | train accuracy: 0.16222 | test accuracy: 0.37778\n",
      "epoch:   4 | train accuracy: 0.42667 | test accuracy: 0.56667\n",
      "epoch:   5 | train accuracy: 0.55778 | test accuracy: 0.56667\n",
      "epoch:   6 | train accuracy: 0.63333 | test accuracy: 0.77778\n",
      "epoch:   7 | train accuracy: 0.71778 | test accuracy: 0.81111\n",
      "epoch:   8 | train accuracy: 0.80222 | test accuracy: 0.81111\n",
      "epoch:   9 | train accuracy: 0.78444 | test accuracy: 0.74444\n",
      "epoch:  10 | train accuracy: 0.81111 | test accuracy: 0.82222\n",
      "Subset 1\n",
      "epoch:   1 | train accuracy: 0.11778 | test accuracy: 0.18889\n",
      "epoch:   2 | train accuracy: 0.25111 | test accuracy: 0.33333\n",
      "epoch:   3 | train accuracy: 0.30000 | test accuracy: 0.35556\n",
      "epoch:   4 | train accuracy: 0.55778 | test accuracy: 0.55556\n",
      "epoch:   5 | train accuracy: 0.60889 | test accuracy: 0.63333\n",
      "epoch:   6 | train accuracy: 0.68667 | test accuracy: 0.67778\n",
      "epoch:   7 | train accuracy: 0.73556 | test accuracy: 0.67778\n",
      "epoch:   8 | train accuracy: 0.80444 | test accuracy: 0.78889\n",
      "epoch:   9 | train accuracy: 0.77111 | test accuracy: 0.77778\n",
      "epoch:  10 | train accuracy: 0.83111 | test accuracy: 0.80000\n",
      "Subset 2\n",
      "epoch:   1 | train accuracy: 0.12000 | test accuracy: 0.22222\n",
      "epoch:   2 | train accuracy: 0.15556 | test accuracy: 0.11111\n",
      "epoch:   3 | train accuracy: 0.25333 | test accuracy: 0.37778\n",
      "epoch:   4 | train accuracy: 0.38889 | test accuracy: 0.51111\n",
      "epoch:   5 | train accuracy: 0.67111 | test accuracy: 0.62222\n",
      "epoch:   6 | train accuracy: 0.70444 | test accuracy: 0.67778\n",
      "epoch:   7 | train accuracy: 0.77778 | test accuracy: 0.66667\n",
      "epoch:   8 | train accuracy: 0.72889 | test accuracy: 0.66667\n",
      "epoch:   9 | train accuracy: 0.78444 | test accuracy: 0.74444\n",
      "epoch:  10 | train accuracy: 0.83333 | test accuracy: 0.74444\n"
     ]
    }
   ],
   "source": [
    "# start_train_end_node_process()\n",
    "start_train_end_node_process_print_some(number_of_samples, print_amount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.0088, -0.0085,  0.0256,  0.0047, -0.0443], grad_fn=<SliceBackward>)\n",
      "tensor([-0.0200, -0.0078,  0.0206,  0.0054, -0.0463], grad_fn=<SliceBackward>)\n"
     ]
    }
   ],
   "source": [
    "## As you can see, wieghts of local models are updated after training process\n",
    "print(main_model.fc2.weight[0,0:5])\n",
    "print(model_dict[\"model1\"].fc2.weight[0,0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's compare the performance of federated main model, individual local models and centralized model  \n",
    "\n",
    "**Federated main model vs individual local models before 1st iteration (on distributed test set)**  \n",
    "Since main model is randomly initialized and no action taken on it yet, its performance is very poor. Please before_acc_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "before_acc_table=compare_local_and_merged_model_performance(number_of_samples=number_of_samples)\n",
    "before_test_loss, before_test_accuracy = validation(main_model, test_dl, main_criterion)\n",
    "\n",
    "main_model= set_averaged_weights_as_main_model_weights_and_update_main_model(main_model,model_dict, number_of_samples) \n",
    "\n",
    "after_acc_table=compare_local_and_merged_model_performance(number_of_samples=number_of_samples)\n",
    "after_test_loss, after_test_accuracy = validation(main_model, test_dl, main_criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Federated main model vs individual local models before FedAvg first iteration\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample</th>\n",
       "      <th>local_ind_model</th>\n",
       "      <th>merged_main_model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sample 0</td>\n",
       "      <td>0.8222</td>\n",
       "      <td>0.0889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sample 1</td>\n",
       "      <td>0.8000</td>\n",
       "      <td>0.1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sample 2</td>\n",
       "      <td>0.7444</td>\n",
       "      <td>0.1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sample 3</td>\n",
       "      <td>0.8111</td>\n",
       "      <td>0.0889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sample 4</td>\n",
       "      <td>0.8222</td>\n",
       "      <td>0.0778</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sample  local_ind_model  merged_main_model\n",
       "0  sample 0           0.8222             0.0889\n",
       "1  sample 1           0.8000             0.1000\n",
       "2  sample 2           0.7444             0.1000\n",
       "3  sample 3           0.8111             0.0889\n",
       "4  sample 4           0.8222             0.0778"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Federated main model vs individual local models before FedAvg first iteration\")\n",
    "before_acc_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Federated main model vs individual local models after FedAvg first iteration\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample</th>\n",
       "      <th>local_ind_model</th>\n",
       "      <th>merged_main_model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sample 0</td>\n",
       "      <td>0.8222</td>\n",
       "      <td>0.9222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sample 1</td>\n",
       "      <td>0.8000</td>\n",
       "      <td>0.8333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sample 2</td>\n",
       "      <td>0.7444</td>\n",
       "      <td>0.7889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sample 3</td>\n",
       "      <td>0.8111</td>\n",
       "      <td>0.8556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sample 4</td>\n",
       "      <td>0.8222</td>\n",
       "      <td>0.8667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sample  local_ind_model  merged_main_model\n",
       "0  sample 0           0.8222             0.9222\n",
       "1  sample 1           0.8000             0.8333\n",
       "2  sample 2           0.7444             0.7889\n",
       "3  sample 3           0.8111             0.8556\n",
       "4  sample 4           0.8222             0.8667"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Federated main model vs individual local models after FedAvg first iteration\")\n",
    "after_acc_table.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Federated main model vs centralized model before 1st iteration (on all test data)**  \n",
    "Please be aware that the centralized model gets approximately %98 accuracy on all test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before 1st iteration main model accuracy on all test data:  0.0865\n",
      "After 1st iteration main model accuracy on all test data:  0.8590\n",
      "Centralized model accuracy on all test data:  0.9798\n"
     ]
    }
   ],
   "source": [
    "print(\"Before 1st iteration main model accuracy on all test data: {:7.4f}\".format(before_test_accuracy))\n",
    "print(\"After 1st iteration main model accuracy on all test data: {:7.4f}\".format(after_test_accuracy))\n",
    "print(\"Centralized model accuracy on all test data: {:7.4f}\".format(central_test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a single iteration, we can send the weights of the main model back to the nodes and repeat the above steps.\n",
    "Now let's check how the performance of the main model improves when we repeat the iteration 10 more times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2 : main_model accuracy on all test data:  0.8986\n",
      "Iteration 3 : main_model accuracy on all test data:  0.9093\n",
      "Iteration 4 : main_model accuracy on all test data:  0.9162\n",
      "Iteration 5 : main_model accuracy on all test data:  0.9225\n",
      "Iteration 6 : main_model accuracy on all test data:  0.9273\n",
      "Iteration 7 : main_model accuracy on all test data:  0.9328\n",
      "Iteration 8 : main_model accuracy on all test data:  0.9356\n",
      "Iteration 9 : main_model accuracy on all test data:  0.9390\n",
      "Iteration 10 : main_model accuracy on all test data:  0.9423\n",
      "Iteration 11 : main_model accuracy on all test data:  0.9443\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    model_dict=send_main_model_to_nodes_and_update_model_dict(main_model, model_dict, number_of_samples)\n",
    "    start_train_end_node_process_without_print(number_of_samples)\n",
    "    main_model= set_averaged_weights_as_main_model_weights_and_update_main_model(main_model,model_dict, number_of_samples) \n",
    "    test_loss, test_accuracy = validation(main_model, test_dl, main_criterion)\n",
    "    print(\"Iteration\", str(i+2), \": main_model accuracy on all test data: {:7.4f}\".format(test_accuracy))   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of the centralized model was calculated as approximately 98%. The accuracy of the main model obtained by FedAvg method started from 85% and improved to 94%. In this case, we can say that although the main model obtained by FedAvg method was trained without seeing the data, its performance cannot be underestimated."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
